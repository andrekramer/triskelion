"""Triskelion Flask Web App"""
# partly generated by Gemini AI
from flask import Flask, request, render_template, jsonify

from multillm import run_comparison
from config import configure, web_comparisons, default_web_comparison
from config import schedule, comparison_schedule
from config import models, comparison_models, Config

configure()
DEV = True

app = Flask(__name__)


@app.route('/prompt', methods=['POST'])
async def prompt_comparison():
    """prompt web methdd"""
    try:
        data = request.get_json()
        if not data or 'prompt' not in data:
            return jsonify({"error": "Invalid request: 'prompt' field is required."}), 400

        prompt = data['prompt']
        action = data.get("action", "3-way")
        trail = await run_comparison(prompt, action)

        response_text = trail[-1]
        response = {"compared_response": response_text}
        return jsonify(response), 200

    except Exception as e:
        return jsonify({"error": f"Error processing the prompt: {str(e)}"}), 500


@app.route("/", methods=["GET", "POST"])
async def index():
    """main web methdd"""
    if request.method == "POST":
        input_text = request.form["text_input"]
        selected_comp = request.form.get("comp", str(default_web_comparison))
        print("selected comp " + selected_comp)

        if input_text is None or input_text.strip() == "":
            return render_template("index.html", selected_comp=selected_comp, comps=web_comparisons)

        response_lines = await process_prompt(input_text, selected_comp)

        return render_template("index.html",
                               response=response_lines,
                               prompt=input_text,
                               selected_comp=selected_comp,
                               comps=web_comparisons) # Render the HTML page

    return render_template("index.html",
                           selected_comp="1",
                           comps=web_comparisons) # renders the page on a GET request


@app.route('/config', methods=['GET', 'POST'])
def configure_comparison():
    """configure web methdd"""
    feature_sets, selected_options = get_features()

    if request.method == 'POST':
        selected_options = request.form.getlist('selected_options')
        # Process the selected checkboxes

        print(f"Selected Options: {selected_options}")

        config_models(selected_options)

        Config.set_single_comparator("single-compare" in selected_options)
        Config.set_diff_comparator("diff-comparisons" in selected_options)
        Config.set_justify("justify" in selected_options)
        Config.set_include_query("comapre_answers" in selected_options)

        return jsonify(selected_options)

    return render_template('config.html',
                           feature_sets=feature_sets,
                           selected_options=selected_options)

def get_features():
    """get feature settings"""
    feature_sets = {
        "set_models": {
            "name": "Models",
            "options": []
        },
        "set_comparison_models": {
            "name": "Comparison Models",
            "options": []
        },
        "others": {
           "name": "Others",
           "options": []
        }
    }

    selected_options = [""]
    options = []
    for model in models:
        if not model.name in schedule:
            continue
        if schedule[model.name]:
            selected_options.append("model-" + model.name)
        options.append({
           "name": model.name,
           "id": "model-" + model.name
        })
    feature_sets["set_models"]["options"] = options

    options = []
    for model in comparison_models:
        if not model.name in comparison_schedule:
            continue
        if comparison_schedule[model.name]:
            selected_options.append("comparison-model-" + model.name)
        options.append({
           "name": model.name,
           "id": "comparison-model-" + model.name
        })
    feature_sets["set_comparison_models"]["options"] = options

    options = []
    if Config.get_single_comparator():
        selected_options.append("single-compare")
    if Config.get_diff_comparator():
        selected_options.append("diff-comparisons")
    if Config.get_justify():
        selected_options.append("justify")
    if Config.get_include_query():
        selected_options.append("compare_answers")

    options.append({
       "name": "use first model for all comparisons",
        "id": "single-compare"
    })
    options.append({
       "name": "or use different model for comparisons or each in turn",
        "id": "diff-comparisons"
    })
    options.append({
        "name": "justify comparisons",
        "id": "justify"
    })
    options.append({
        "name": "include query in comparison prompts",
        "id": "compare_answers"
    })

    feature_sets["others"]["options"] = options

    return (feature_sets, selected_options)

def config_models(selected_options):
    """configure models"""
    schedule2 = {}
    for m in schedule:
        schedule2[m] = False
    comparison_schedule2 = {}
    for cm in comparison_schedule:
        comparison_schedule2[cm] = False

    for option in selected_options:
        if option.startswith("model-"):
            m = option[6:]
            print("selected model " + m)
            schedule2[m] = True
        elif option.startswith("comparison-model-"):
            cm = option[17:]
            print("selected comparison model " + cm)
            comparison_schedule2[cm] = True

    for k,v in schedule2.items():
        schedule[k] = v
    for k,v in comparison_schedule2.items():
        comparison_schedule[k] = v

async def process_prompt(prompt, selected_comp):
    """process the prompt by running a comparison"""
    try:
        i = int(selected_comp)
        comp = web_comparisons[i]

        result = await run_comparison(prompt, comp) # respond with a list of strings
        return result
    except Exception as e:
        return ["failed to run comparison", str(e)]


if __name__ == "__main__":
    Config.set_trail_only(DEV)
    app.run(debug=DEV)
